import streamlit as st
import anthropic
import PyPDF2
import io
import requests
from scholarly import scholarly
from Bio import Entrez
import json
import re

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ë³‘ë¦¬í•™ ë¶„ì•¼ì˜ ì—°êµ¬ ì „ë¬¸ê°€ë¡œì„œ í–‰ë™í•˜ëŠ” AI ì¡°ìˆ˜ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì—­í• ì€ ì‚¬ìš©ìê°€ ì—°êµ¬ê³„íšì„œë¥¼ ì‘ì„±í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì—°êµ¬ê³„íšì„œì˜ íŠ¹ì • í•­ëª©ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•  ê²ƒì´ë©°, ë‹¹ì‹ ì€ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ í•­ëª©ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ì£¼ì˜ ê¹Šê²Œ ë¶„ì„í•˜ê³ , ë‹¹ì‹ ì˜ ë³‘ë¦¬í•™ ì—°êµ¬ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ìš”ì²­ëœ ì—°êµ¬ê³„íšì„œ ì„¹ì…˜ì„ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”:

1. ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”.
2. í•„ìš”í•œ ê²½ìš°, ë³‘ë¦¬í•™ ì—°êµ¬ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •ë³´ë¥¼ ë³´ì™„í•˜ì„¸ìš”.
3. ì—°êµ¬ê³„íšì„œ ì„¹ì…˜ì˜ êµ¬ì¡°ì™€ í˜•ì‹ì„ ì ì ˆíˆ ìœ ì§€í•˜ì„¸ìš”.
4. ëª…í™•í•˜ê³  ì „ë¬¸ì ì¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
5. í•„ìš”í•œ ê²½ìš° ì ì ˆí•œ ì°¸ê³ ë¬¸í—Œì´ë‚˜ ì¸ìš©ì„ í¬í•¨í•˜ì„¸ìš”.

í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜ ì˜í•™ ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ì˜ì–´ ì›ë¬¸ì„ í¬í•¨ì‹œí‚¤ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, "ì—½ìƒì¢…ì–‘(Phyllodes tumor)"ê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""

# PREDEFINED_PROMPTS ìˆ˜ì •
PREDEFINED_PROMPTS = {
    "2. ì—°êµ¬ ëª©ì ": """
    ì‚¬ìš©ìê°€ ì œê³µí•œ ì—°êµ¬ ì£¼ì œì™€ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì—°êµ¬ ëª©ì ê³¼ ê°€ì„¤ì„ 1000ì ì´ë‚´ì˜ ì¤„ê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì–´ë¯¸ëŠ” ë°˜ë§ ë¬¸ì–´ì²´ë¡œ í•©ë‹ˆë‹¤. (ì˜ˆ: ~í•˜ì˜€ë‹¤. ~ìˆë‹¤. ~ìˆì—ˆë‹¤)
    ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
    1. ì—°êµ¬ì˜ ì£¼ìš” ëª©ì 
    2. ì—°êµ¬ë¡œ ì¸í•´ ì˜ë„í•˜ëŠ” ê°€ì„¤
    3. ê°€ì„¤ì„ ì…ì¦í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ì„¤ëª…
    4. ì—°êµ¬ì˜ ì¤‘ìš”ì„±ê³¼ ì˜ˆìƒë˜ëŠ” ê²°ê³¼

    ì‚¬ìš©ì ì…ë ¥:
    {user_input}

    ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°êµ¬ ëª©ì ê³¼ ê°€ì„¤ì„ êµ¬ì²´í™”í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """,
    "3. ì—°êµ¬ ë°°ê²½": """
    ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—°êµ¬ì˜ ë°°ê²½ì„ 1500ì ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì–´ë¯¸ëŠ” ë°˜ë§ ë¬¸ì–´ì²´ë¡œ í•©ë‹ˆë‹¤. (ì˜ˆ: ~í•˜ì˜€ë‹¤. ~ìˆë‹¤. ~ìˆì—ˆë‹¤)
    ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”:
    1. ì´ë¡ ì  ë°°ê²½ ë° ê·¼ê±°
    2. ì„ í–‰ ì—°êµ¬ ë° ê²°ê³¼
    3. ì—°êµ¬ ë°°ê²½ê³¼ ì—°êµ¬ì˜ ì •ë‹¹ì„±ì— ëŒ€í•œ ì„¤ëª…
    4. êµ­ë‚´ì™¸ ì—°êµ¬ í˜„í™©

    ì‚¬ìš©ì ì…ë ¥:
    {user_input}

    ì—°êµ¬ ëª©ì :
    {research_purpose}

    ê²€ìƒ‰ëœ ë…¼ë¬¸:
    {papers}

    PDF ë‚´ìš©:
    {pdf_content}

    ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°êµ¬ ë°°ê²½ì„ êµ¬ì²´í™”í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”. ì°¸ê³ ë¬¸í—Œì„ ì¸ìš©í•  ë•ŒëŠ” [ì €ì, ì—°ë„] í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´ì£¼ì„¸ìš”.
    """,

    "4. ì„ ì •ê¸°ì¤€": """
    2, 3ë²ˆ ì„¹ì…˜ì˜ ê²°ê³¼ë¬¼ê³¼ ì°¸ê³ í•œ ë…¼ë¬¸ë“¤ì„ í† ëŒ€ë¡œ, ì´ ì—°êµ¬ì— ì ë‹¹í•œ ëŒ€ìƒì ê·¸ë£¹ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ì£¼ì„¸ìš”:
    1. êµ¬ì²´ì ì¸ ë…„ë„ë‚˜ ì‹œê¸°ëŠ” ì ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì˜ëª»ëœ ì˜ˆì‹œ: 2009ë…„ êµ­ê°€ ê±´ê°•ê²€ì§„ì„ ë°›ì€ 4,234,415ëª…)
    2. ì–´ë¯¸ëŠ” ì ì§€ ì•Šê³  ë‹¨ì–´ë¡œ ë¬¸ì¥ì„ ëëƒ…ë‹ˆë‹¤.
    3. ì„ ì •ê¸°ì¤€ ì˜ˆì‹œ: 40ì„¸ì—ì„œ 60ì„¸ ì‚¬ì´ì— í•´ë‹¹í•˜ë©°, ì´ì „ ì¹˜ë§¤ì— ì§„ë‹¨ë°›ì€ ê³¼ê±°ë ¥ì´ ì—†ëŠ” ìˆ˜ê²€ì

    ì—°êµ¬ ëª©ì :
    {research_purpose}

    ì—°êµ¬ ë°°ê²½:
    {research_background}

    ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì„ ì •ê¸°ì¤€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
}


# ì—°êµ¬ ì„¹ì…˜ ìˆœì„œ ì •ì˜
RESEARCH_SECTIONS = [
    "2. ì—°êµ¬ ëª©ì ",
    "3. ì—°êµ¬ ë°°ê²½",
    "4. ì„ ì •ê¸°ì¤€",
    # ë‹¤ë¥¸ ì„¹ì…˜ë“¤ì€ ë‚˜ì¤‘ì— ì¶”ê°€í•  ì˜ˆì •ì…ë‹ˆë‹¤.
]

# Anthropic API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_anthropic_client(api_key):
    try:
        client = anthropic.Client(api_key=api_key)
        # ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ í‚¤ ìœ íš¨ì„± ê²€ì‚¬
        client.messages.create(
            model="claude-3-5-sonnet-20240620",
            max_tokens=2000,
            messages=[{"role": "user", "content": "Hello"}]
        )
        return client
    except Exception as e:
        st.error(f"API í‚¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

#ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜
def reset_session():
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    st.session_state.clear()

                
#AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_ai_response(prompt):
    if 'anthropic_client' in st.session_state and st.session_state.anthropic_client:
        try:
            system_prompt = f"{SYSTEM_PROMPT}\n\nì¶”ê°€ ì§€ì‹œì‚¬í•­: ë‹µë³€ì„ ì‘ì„±í•  ë•Œ ë²ˆí˜¸ë‚˜ ë¶ˆë › í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë¬¸ë‹¨ì„ ë‚˜ëˆ„ì–´ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ë˜, ì „ì²´ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ì—°ê²°ëœ ê¸€ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”."
            
            response = st.session_state.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20240620",
                max_tokens=2000,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
        except anthropic.APIError as e:
            st.error(f"Anthropic API ì˜¤ë¥˜: {str(e)}")
            return f"AI ì‘ë‹µ ìƒì„± ì¤‘ API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        except Exception as e:
            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return f"AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    else:
        return "API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."


# PDF íŒŒì¼ ì—…ë¡œë“œ í•¨ìˆ˜
def upload_pdf():
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")
    if uploaded_file is not None:
        return extract_text_from_pdf(uploaded_file)
    return None

# PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_pdf(file):
    pdf_reader = PyPDF2.PdfReader(io.BytesIO(file.getvalue()))
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    return text

# PubMed ê²€ìƒ‰ í•¨ìˆ˜ (ìˆ˜ì •)
def search_pubmed(query, max_results=10):
    Entrez.email = "your_email@example.com"
    handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results)
    record = Entrez.read(handle)
    handle.close()
    
    ids = record["IdList"]
    results = []
    for id in ids:
        handle = Entrez.efetch(db="pubmed", id=id, rettype="medline", retmode="text")
        record = Entrez.read(Entrez.parse(handle))
        if record:
            article = record[0]
            title = article.get("TI", "No title")
            year = article.get("DP", "")[:4]  # ì¶œíŒ ì—°ë„
            authors = ", ".join(article.get("AU", []))[:50] + "..." if len(article.get("AU", [])) > 2 else ", ".join(article.get("AU", []))
            link = f"https://pubmed.ncbi.nlm.nih.gov/{id}/"
            results.append({"title": title, "year": year, "authors": authors, "link": link})
        handle.close()
    return results

# Google Scholar ê²€ìƒ‰ í•¨ìˆ˜ ìˆ˜ì •
def search_google_scholar(query, max_results=10):
    search_query = scholarly.search_pubs(query)
    results = []
    for i, result in enumerate(search_query):
        if i >= max_results:
            break
        try:
            title = result['bib'].get('title', 'No title')
            year = result['bib'].get('pub_year', 'No year')
            authors = result['bib'].get('author', 'No author')
            if isinstance(authors, list):
                authors = ", ".join(authors[:2]) + "..." if len(authors) > 2 else ", ".join(authors)
            link = result.get('pub_url', '#')
            results.append({"title": title, "year": year, "authors": authors, "link": link})
        except AttributeError:
            continue  # ê²°ê³¼ë¥¼ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ê²°ê³¼ë¡œ ì§„í–‰
    return results


def show_chat_interface():
    current_item = st.session_state.get('current_item', '')
    if current_item:
        st.markdown(f"**í˜„ì¬ ì‘ì„± ì¤‘ì¸ í•­ëª©: {current_item}**")
        instruction = SYSTEM_PROMPTS['prompts'].get(current_item, "ì´ í•­ëª©ì— ëŒ€í•´ ì–´ë–¤ ë‚´ìš©ì„ ì‘ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
        st.info(instruction)

    for message in st.session_state.get('messages', []):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        response = generate_ai_response(prompt, current_item)
        st.session_state.messages.append({"role": "assistant", "content": response})
        with st.chat_message("assistant"):
            st.markdown(response)
        
        # í•­ëª© ì™„ë£Œ ì²˜ë¦¬
        if current_item not in st.session_state.get('completed_items', []):
            st.session_state.completed_items = st.session_state.get('completed_items', []) + [current_item]
        
        # ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ìë™ ì´ë™
        items = list(SYSTEM_PROMPTS['prompts'].keys())
        current_index = items.index(current_item)
        if current_index < len(items) - 1:
            next_item = items[current_index + 1]
            st.session_state.current_item = next_item
            st.info(f"ë‹¤ìŒ í•­ëª© '{next_item}'ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        else:
            st.success("ëª¨ë“  í•­ëª© ì‘ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        st.rerun()

def write_research_purpose():
    st.markdown("## 2. ì—°êµ¬ ëª©ì ")
    st.markdown("ì–´ë–¤ ì—°êµ¬ë¥¼ ê³„íšì¤‘ì¸ì§€, ì—°êµ¬ì— ëŒ€í•œ ë‚´ìš©ì´ë‚˜ í‚¤ì›Œë“œë¥¼ í˜•ì‹ì— ìƒê´€ì—†ì´ ììœ ë¡­ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”. ì…ë ¥ í›„ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ AI ëª¨ë¸ì´ ì—°êµ¬ëª©ì ì— ëŒ€í•œ ì¤„ê¸€ì„ ì‘ì„± í•´ ì¤ë‹ˆë‹¤.")
    
    user_input = st.text_area("ì—°êµ¬ ì£¼ì œ ë° í‚¤ì›Œë“œ:", height=150)
    
    if st.button("ì—°êµ¬ ëª©ì  ìƒì„±"):
        if user_input:
            prompt = PREDEFINED_PROMPTS["2. ì—°êµ¬ ëª©ì "].format(user_input=user_input)
            ai_response = generate_ai_response(prompt)
            
            st.session_state.section_contents["2. ì—°êµ¬ ëª©ì "] = ai_response
            st.markdown("### AIê°€ ìƒì„±í•œ ì—°êµ¬ ëª©ì :")
            st.markdown(ai_response)
            
            # ê¸€ì ìˆ˜ í™•ì¸
            char_count = len(ai_response)
            st.info(f"ìƒì„±ëœ ë‚´ìš©ì˜ ê¸€ì ìˆ˜: {char_count}/1000")
            
            if char_count > 1000:
                st.warning("ìƒì„±ëœ ë‚´ìš©ì´ 1000ìë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì—°êµ¬ ì£¼ì œë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # í¸ì§‘ ê¸°ëŠ¥
    if "2. ì—°êµ¬ ëª©ì " in st.session_state.section_contents:
        edited_content = st.text_area(
            "ìƒì„±ëœ ë‚´ìš©ì„ í¸ì§‘í•˜ì„¸ìš”:",
            st.session_state.section_contents["2. ì—°êµ¬ ëª©ì "],
            height=300
        )
        if st.button("í¸ì§‘ ë‚´ìš© ì €ì¥"):
            st.session_state.section_contents["2. ì—°êµ¬ ëª©ì "] = edited_content
            st.success("í¸ì§‘ëœ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ì—°êµ¬ ë°°ê²½ ì‘ì„± í•¨ìˆ˜ (ìˆ˜ì •)
def write_research_background():
    st.markdown("## 3. ì—°êµ¬ ë°°ê²½")
    
    # í‚¤ì›Œë“œ ì…ë ¥
    keywords = st.text_input("ì—°êµ¬ ë°°ê²½ ì‘ì„±ì„ ìœ„í•œ ì°¸ì¡°ë…¼ë¬¸ ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ìµœëŒ€ 10ê°œ, ì‰¼í‘œë¡œ êµ¬ë¶„):")
    keywords_list = [k.strip() for k in keywords.split(',') if k.strip()][:10]
    
    if keywords_list:
        st.write("ì…ë ¥ëœ í‚¤ì›Œë“œ:", ", ".join(keywords_list))
        
    if st.button("ë…¼ë¬¸ ê²€ìƒ‰"):
        if keywords_list:
            search_query = " ".join(keywords_list)
            
            with st.spinner("ë…¼ë¬¸ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                pubmed_results = search_pubmed(search_query)
                scholar_results = search_google_scholar(search_query)
            
            st.success("ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # PubMed ê²°ê³¼ í‘œì‹œ
            st.subheader("PubMed ê²€ìƒ‰ ê²°ê³¼")
            for i, result in enumerate(pubmed_results):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"[{result['title']} ({result['year']})]({result['link']})")
                    st.caption(f"ì €ì: {result['authors']}")
                with col2:
                    if st.button("ì‚­ì œ", key=f"del_pubmed_{i}"):
                        del pubmed_results[i]
                        st.rerun()
            
           # Google Scholar ê²°ê³¼ í‘œì‹œ
            st.subheader("Google Scholar ê²€ìƒ‰ ê²°ê³¼")
            for i, result in enumerate(scholar_results):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"[{result['title']} ({result['year']})]({result['link']})")
                    st.caption(f"ì €ì: {result['authors']}")
                with col2:
                    if st.button("ì‚­ì œ", key=f"del_scholar_{i}"):
                        del scholar_results[i]
                        st.rerun()
            
            # ê²€ìƒ‰ ê²°ê³¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.pubmed_results = pubmed_results
            st.session_state.scholar_results = scholar_results
        else:
            st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
    # PDF íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader("ì—°êµ¬ ë°°ê²½ ì‘ì„±ì— ì°¸ê³ í•  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)", type="pdf", accept_multiple_files=True)
    
    pdf_texts = []
    if uploaded_files:
        for uploaded_file in uploaded_files:
            pdf_text = extract_text_from_pdf(uploaded_file)
            pdf_texts.append(pdf_text)
        st.success(f"{len(uploaded_files)}ê°œì˜ PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì—°êµ¬ ë°°ê²½ ìƒì„± ë²„íŠ¼
    if st.button("í•´ë‹¹ ë‚´ìš©ìœ¼ë¡œ ì—°êµ¬ë°°ê²½ ì‘ì„±í•˜ê¸°"):
        if 'pubmed_results' in st.session_state or 'scholar_results' in st.session_state or pdf_texts:
            # ì—°êµ¬ ëª©ì  ê°€ì ¸ì˜¤ê¸°
            research_purpose = st.session_state.section_contents.get("2. ì—°êµ¬ ëª©ì ", "")
            
            # ê²€ìƒ‰ ê²°ê³¼ ë° PDF ë‚´ìš© ê²°í•©
            papers = []
            if 'pubmed_results' in st.session_state:
                papers.extend([f"{r['title']} ({r['year']})" for r in st.session_state.pubmed_results])
            if 'scholar_results' in st.session_state:
                papers.extend([f"{r['title']} ({r['year']})" for r in st.session_state.scholar_results])
            papers_text = "\n".join(papers)
            
            pdf_content = "\n".join(pdf_texts)
            
            # AIì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = PREDEFINED_PROMPTS["3. ì—°êµ¬ ë°°ê²½"].format(
                user_input=keywords,
                research_purpose=research_purpose,
                papers=papers_text,
                pdf_content=pdf_content[:1000]  # PDF ë‚´ìš©ì€ 1000ìë¡œ ì œí•œ
            )
            
            # AI ì‘ë‹µ ìƒì„±
            ai_response = generate_ai_response(prompt)
            
            st.session_state.section_contents["3. ì—°êµ¬ ë°°ê²½"] = ai_response
            st.markdown("### AIê°€ ìƒì„±í•œ ì—°êµ¬ ë°°ê²½:")
            st.markdown(ai_response)
            
            # ê¸€ì ìˆ˜ í™•ì¸
            char_count = len(ai_response)
            st.info(f"ìƒì„±ëœ ë‚´ìš©ì˜ ê¸€ì ìˆ˜: {char_count}/1500")
            
            if char_count > 1500:
                st.warning("ìƒì„±ëœ ë‚´ìš©ì´ 1500ìë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê±°ë‚˜ PDFë¥¼ ì—…ë¡œë“œí•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    # í¸ì§‘ ê¸°ëŠ¥
    if "3. ì—°êµ¬ ë°°ê²½" in st.session_state.section_contents:
        edited_content = st.text_area(
            "ìƒì„±ëœ ë‚´ìš©ì„ í¸ì§‘í•˜ì„¸ìš”:",
            st.session_state.section_contents["3. ì—°êµ¬ ë°°ê²½"],
            height=300
        )
        if st.button("í¸ì§‘ ë‚´ìš© ì €ì¥"):
            st.session_state.section_contents["3. ì—°êµ¬ ë°°ê²½"] = edited_content
            st.success("í¸ì§‘ëœ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì„ ì •ê¸°ì¤€ ì‘ì„± í•¨ìˆ˜
def write_selection_criteria():
    st.markdown("## 4. ì„ ì •ê¸°ì¤€")
    
    # í¸ì§‘ ê¸°ëŠ¥ (AI ì¶”ì²œ ì „ì—ë„ í‘œì‹œ)
    edited_content = st.text_area(
        "ìƒì„±ëœ ë‚´ìš©ì„ í¸ì§‘í•˜ê±°ë‚˜, ì„ ì •ê¸°ì¤€ì„ ì§ì ‘ ì‘ì„±í•˜ì„¸ìš”:",
        st.session_state.section_contents.get("4. ì„ ì •ê¸°ì¤€", ""),
        height=200
    )
    
    if st.button("ì„ ì •ê¸°ì¤€ AIì—ê²Œ ì¶”ì²œë°›ê¸°"):
        research_purpose = st.session_state.section_contents.get("2. ì—°êµ¬ ëª©ì ", "")
        research_background = st.session_state.section_contents.get("3. ì—°êµ¬ ë°°ê²½", "")
        
        prompt = PREDEFINED_PROMPTS["4. ì„ ì •ê¸°ì¤€"].format(
            research_purpose=research_purpose,
            research_background=research_background
        )
        
        ai_response = generate_ai_response(prompt)
        
        st.session_state.section_contents["4. ì„ ì •ê¸°ì¤€"] = ai_response
        st.markdown("### AIê°€ ì¶”ì²œí•œ ì„ ì •ê¸°ì¤€:")
        st.markdown(ai_response)
    
    if st.button("í¸ì§‘ ë‚´ìš© ì €ì¥"):
        st.session_state.section_contents["4. ì„ ì •ê¸°ì¤€"] = edited_content
        st.success("í¸ì§‘ëœ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def extract_references(text):
    # [ì €ì, ì—°ë„] í˜•ì‹ì˜ ì°¸ê³ ë¬¸í—Œì„ ì¶”ì¶œ
    references = re.findall(r'\[([^\]]+)\]', text)
    return list(set(references))  # ì¤‘ë³µ ì œê±°

# ì—¬ê¸°ì— chat_interface í•¨ìˆ˜ê°€ ì´ì–´ì§‘ë‹ˆë‹¤.

def chat_interface():
    st.subheader("ì—°êµ¬ê³„íšì„œ ì‘ì„± ì±„íŒ…")

    if 'api_key' not in st.session_state or not st.session_state.api_key:
        api_key = st.text_input("Anthropic API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
        
        # API í‚¤ í™•ì¸ ë²„íŠ¼
        if st.button("API í‚¤ í™•ì¸"):
            client = initialize_anthropic_client(api_key)
            if client:
                st.success("ìœ íš¨í•œ API í‚¤ì…ë‹ˆë‹¤. ì—°êµ¬ê³„íšì„œ ì‘ì„±í•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”.")
                st.session_state.temp_api_key = api_key  # ì„ì‹œë¡œ API í‚¤ ì €ì¥
            else:
                st.error("API í‚¤ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        
        # ì—°êµ¬ê³„íšì„œ ì‘ì„±í•˜ê¸° ë²„íŠ¼
        if st.button("ì—°êµ¬ê³„íšì„œ ì‘ì„±í•˜ê¸°âœï¸"):
            if 'temp_api_key' in st.session_state:
                st.session_state.api_key = st.session_state.temp_api_key
                st.session_state.anthropic_client = initialize_anthropic_client(st.session_state.api_key)
                del st.session_state.temp_api_key  # ì„ì‹œ ì €ì¥ëœ API í‚¤ ì‚­ì œ
                st.success("API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.warning("ë¨¼ì € API í‚¤ë¥¼ ì…ë ¥í•˜ê³  í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        # API í‚¤ê°€ ì´ë¯¸ ì„¤ì •ëœ ê²½ìš°ì˜ ë¡œì§
        if 'current_section' not in st.session_state:
            st.session_state.current_section = RESEARCH_SECTIONS[0]
        if 'section_contents' not in st.session_state:
            st.session_state.section_contents = {}
        if 'references' not in st.session_state:
            st.session_state.references = []  # ì°¸ê³ ë¬¸í—Œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

        if 'api_key' in st.session_state:
            st.sidebar.text(f"í˜„ì¬ API í‚¤: {st.session_state.api_key[:5]}...")
        
    
        
        if st.sidebar.button("ğŸ í™ˆìœ¼ë¡œ"):
            reset_session()
            st.rerun()

        # í˜„ì¬ ì„¹ì…˜ì— ë”°ë¥¸ ì‘ì„± ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
        if st.session_state.current_section == "2. ì—°êµ¬ ëª©ì ":
            write_research_purpose()
        elif st.session_state.current_section == "3. ì—°êµ¬ ë°°ê²½":
            write_research_background()
        elif st.session_state.current_section == "4. ì„ ì •ê¸°ì¤€":
            write_selection_criteria()
             # ... (ë‹¤ë¥¸ ì„¹ì…˜ë“¤ì— ëŒ€í•œ ì¡°ê±´ë¬¸ ì¶”ê°€)

      # ë‹¤ìŒ ì„¹ì…˜ìœ¼ë¡œ ì´ë™
        if st.button("ë‹¤ìŒ ì„¹ì…˜"):
            current_index = RESEARCH_SECTIONS.index(st.session_state.current_section)
            if current_index < len(RESEARCH_SECTIONS) - 1:
                st.session_state.current_section = RESEARCH_SECTIONS[current_index + 1]
                st.rerun()
            else:
                st.success("ëª¨ë“  ì„¹ì…˜ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")

        # ì „ì²´ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        if st.sidebar.button("ì „ì²´ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
            for section in RESEARCH_SECTIONS:
                st.markdown(f"### {section}")
                st.markdown(st.session_state.section_contents.get(section, "ì•„ì§ ì‘ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."))
            
            # ì°¸ê³ ë¬¸í—Œ í‘œì‹œ
            if st.session_state.references:
                st.markdown("### ì°¸ê³ ë¬¸í—Œ")
                for ref in st.session_state.references:
                    st.markdown(f"- {ref}")

    # CSS ìŠ¤íƒ€ì¼ (ì´ì „ê³¼ ë™ì¼)
    st.markdown("""
    <style>
    .stButton>button {
        width: 100%;
        height: 60px;
        white-space: normal;
        word-wrap: break-word;
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    chat_interface()

